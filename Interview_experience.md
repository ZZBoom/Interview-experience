# STL 相关

## vector

概述：vector 与数组类似，拥有一段连续的内存空间，并且起始地址不变。随机访问，时间复杂度为 O(N)。

## List

List 底层是由双向链表实现的，因此内存空间不是连续的。

根据链表的实现原理，List 查询效率较低，时间复杂度为O(N)，但插入和删除效率较高。只需要在插入的地方更改指针的指向即可，不用移动数据。

### vector 的底层原理：

vector 底层是一个动态数组。成员介绍：

capacity: 分配的存储空间的大小

size: 元素的数量

start: 有效元素的起始点

finish: 有效元素的终止点

end_of_storage: 分配内存的界限

### vector 内存增长机制：

每次 push_back，如果没有足够的空间（capacity == size），会自动申请一块更大的空间（1.5倍或者2倍），把原来的数据拷贝到新的内存空间，接着释放原来的那片空间。

有三个迭代器，start 和 finish 之间是已经被使用的空间范围，end_of_storage 是整块连续空间包括备用空间的尾部。

### 删除元素问题 & 迭代器失效问题：

对 vector 的任何操作一旦引起了空间的重新配置，指向原 vector 的所有迭代器会都失效。

当插入一个元素到 vector 中，由于引起了内存重新分配，所以指向原内存的迭代器全部失效。

当删除容器中一个元素后，该迭代器所指向的元素已经被删除，那么也造成迭代器失效。erase 方法会返回下一个有效的迭代器，所以当我们要删除某个元素时，需要 it=vec.erase(it)，

vector 迭代器虽然还是指向当前位置，而且也引起了元素前挪，但是由于删除结点的迭代器就已经失效，指向删除点后面的元素的迭代器也全部失效，所以不能对当前迭代器进行任何操作；


clear()：当释放或者删除里面的数据时，其存储空间不释放，仅仅是清空了里面的数据。

释放内存：vec.clear(); + vec.shrink_to_fit();

### vector 中的 reserve 和 resize 的区别：

reserve 是直接扩充到已经确定的大小，可以减少多次开辟、释放空间的问题（优化 push_back ），可以提高效率，其次还可以减少多次要拷贝数据的问题。

reserve 只是保证 vector 中的空间大小（capacity）最少达到参数所指定的大小 n。reserve 只有一个参数。
resize 可以改变有效空间的大小，也有改变默认值的功能。capacity 的大小也会随着改变。resize 可以有多个参数。

### vector 中的 size 和 capacity 的区别：

size 表示当前 vector 中有多少个元素（finish - start）;
capacity 函数则表示它已经分配的内存中可以容纳多少元素（end_of_storage - start）;

### vector 中 erase 方法与 algorithn 中的 remove 方法区别：

vector 中 erase 方法是真正删除了元素，迭代器不能访问了
remove 只是简单地将元素移到了容器的最后面，迭代器还是可以访问到。因为algorithm通过迭代器进行操作，不知道容器的内部结构，所以无法进行真正的删除。

### 什么情况下用 vector、list 和 deque：

vector 可以随机存储元素（即可以通过公式直接计算出元素地址，而不需要挨个查找），所以在尾部插入删除数据，对象数量变化不大，随机访问频繁的情况下，我们尽可能选择使用 vector 而非 deque，因为 deque 的迭代器比 vector 迭代器复杂很多，使用会复杂一点。

list 不支持随机存储，适用于对象大，对象数量变化频繁，插入和删除频繁，比如写多读少的场景。

而需要从首尾两端进行插入或删除操作的时候需要选择deque。

## priority_queue

底层实现原理：

其底层是用堆来实现的。在优先队列中，队首元素一定是当前队列中优先级最高的那一个。

## unordered_map 及内部实现机制

### 特性：

因为内部实现了哈希表，因此其查找速度非常的快；

### 缺点：

哈希表的建立比较耗费时间。

与 map 相比比较耗内存。

### 碰撞问题解决手段：

线性探测：顺序往下寻找一个可用的空间为止，最差的情况就是会访问整个表格。

二次探测：奇数 +，偶数 -，每次步长 2^i次。

开链：每个表格维护一个链表，list够短还是比较快的。

### 其他

STL 哈希表是采用开链法

散列表的装填因子：α = 填入表中的元素个数 /散列表的长度

平均查找长度ASL是有计算公式的，ASL的大小可以反映出处理冲突选择的方法的效率

ASL = (查找每个节点我们需要遍历的节点的数目之和) /已经插入的节点的数目

## map、set、multiset、multimap 的底层原理

### 内存分配机制：

元素的内存是动态分配的。map 内部是基于节点的，每个节点都是不同的，在内存中也是不连续的。

底层实现都是红黑树。

### 判断 map 是否存在某个 key，如果不存在，访问了有什么影响：

下标运算符 [key]：如果找不到，它会自动为它创建一个默认的构造元素。可以使用map::at() 成员函数

### 红黑树的特性：

每个结点或是红色或是黑色；
根结点是黑色；
每个叶结点是黑的；
如果一个结点是红的，则它的两个儿子均是黑色；
每个结点到其叶子结点的所有路径上包含相同数目的黑色结点。

### 为何 map 和 set 的插入删除效率比其他序列容器高：

因为不需要内存拷贝和内存移动

### 为何 map 和 set 每次 Insert 之后，以前保存的 iterator 不会失效：

因为插入操作只是结点指针换来换去，结点内存没有改变。

而 iterator就像指向结点的指针，内存没变，指向内存的指针也不会变。

### map、set、multiset、multimap 的特点：

set 和 multiset 会根据特定的排序准则自动将元素排序，set 中元素不允许重复，multiset 可以重复。

map 和 multimap 将 key 和 value 组成的 pair 作为元素，根据 key 的排序准则自动将元素排序（因为红黑树也是二叉搜索树，所以 map 默认是按 key 排序的），map 中元素的 key 不允许重复，multimap可以重复。

map 和 set 的增删改查速度为都是logn，是比较高效的。

### 为何 map 和 set 不能像 vector 一样有个 reserve 函数来预分配数据?

在 map 和 set 内部存储的已经不是元素本身了，而是包含元素的结点。也就是说 map 内部使用的 Alloc 并不是map&lt;Key, Data, Compare, Alloc> 声明的时候从参数中传入的 Alloc。

### set 的底层实现实现为什么不用哈希表而使用红黑树？

set 中元素是经过排序的，红黑树也是有序的，哈希是无序的。
如果只是单纯的查找元素的话，那么肯定要选哈希表了，因为哈希表在的最好查找时间复杂度为 O(1)，并且如果用到 set 中那么查找时间复杂度的一直是 O(N)，因为 set 中是不允许有元素重复的。而红黑树的查找时间复杂度为 O(logn)

### 什么时候用 hash_map，什么时候用 map？

构造函数：hash_map 需要 hash function 和等于函数，而 map 需要比较函数（大于或小于）。

存储结构：hash_map 以 hashtable 为底层，而 map 以 RB-TREE 为底层。

总的说来，hash_map 查找速度比 map 快，而且查找速度基本和数据量大小无关，属于常数级别。而 map 的查找速度是logn级别。但不一定常数就比 log 小，而且 hash_map 还有 hash function 耗时。如果考虑效率，特别当元素达到一定数量级时，用 hash_map。考虑内存，或者元素数量较少时，用map。

# HTTP、TCP等相关网路协议

## 服务端可以建立连接的最大数目由什么决定

{本地ip，本地port，远程ip，远程port}

TCP连出受端口限制,连入仅受内存限制。

每一个TCP链接都要占用一个文件句柄，最高的并发数量都要受到系统对用户单一进程同时可打开文件数量的限制。


ulimit -n


修改网络内核对TCP连接的有关限制（参考对比下篇文章“优化内核参数”）

在高TCP并发的情形下使用同步 I/O是不可取的，这时可以考虑使用非阻塞式同步I/O或异步I/O。

非阻塞式同步I/O的技术包括使用select()，poll()，epoll等机制。

## 三次握手


三次握手（Three-way Handshake）其实就是指建立一个TCP连接时，需要客户端和服务器总共发送3个包。进行三次握手的主要作用就是为了确认双方的接收能力和发送能力是否正常、指定自己的初始化序列号为后面的可靠性传送做准备。实质上其实就是连接服务器指定端口，建立TCP连接，并同步连接双方的序列号和确认号，交换TCP窗口大小信息。

刚开始客户端处于 Closed的状态，服务端处于 Listen状态。

进行三次握手：


第一次握手：客户端给服务端发一个 SYN报文，并指明客户端的初始化序列号 ISN©。此时客户端处于SYN_SEND状态。

首部的同步位SYN=1，初始序号seq=x，SYN=1的报文段不能携带数据，但要消耗掉一个序号。

第二次握手：服务器收到客户端的 SYN报文之后，会以自己的 SYN报文作为应答，并且也是指定了自己的初始化序列号 ISN(s)。同时会把客户端的 ISN + 1作为ACK的值，表示自己已经收到了客户端的SYN，此时服务器处于 SYN_REVD的状态。

在确认报文段中SYN=1，ACK=1，确认号ack=x+1，初始序号seq=y。

第三次握手：客户端收到 SYN报文之后，会发送一个 ACK报文，当然，也是一样把服务器的 ISN + 1作为 ACK的值，表示已经收到了服务端的 SYN报文，此时客户端处于 ESTABLISHED状态。服务器收到ACK报文之后，也处于 ESTABLISHED状态，此时，双方已建立起了连接。

确认报文段ACK=1，确认号ack=y+1，序号seq=x+1（初始为seq=x，第二个报文段所以要+1），ACK报文段可以携带数据，不携带数据则不消耗序号。

发送第一个SYN的一端将执行主动打开（active open），接收这个SYN并发回下一个SYN的另一端执行被动打开（passive open）。

在socket编程中，客户端执行connect()时，将触发三次握手。

### 1.1 为什么需要三次握手，两次不行吗？

主要是为了确保双方都能确定对方的接收能力和发送能力都是 OK的。

弄清这个问题，我们需要先弄明白三次握手的目的是什么，能不能只用两次握手来达到同样的目的。

第一次握手：客户端发送网络包，服务端收到了。

这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。

第二次握手：服务端发包，客户端收到了。

这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。不过此时服务器并不能确认客户端的接收能力是否正常。

第三次握手：客户端发包，服务端收到了。

这样服务端就能得出结论：客户端的接收、发送能力正常，服务器自己的发送、接收能力也正常。

因此，需要三次握手才能确认双方的接收与发送能力是否正常。

试想如果是用两次握手，则会出现下面这种情况：

如客户端发出连接请求，但因连接请求报文丢失而未收到确认，于是客户端再重传一次连接请
求。后来收到了确认，建立了连接。数据传输完毕后，就释放了连接，客户端共发出了两个连接请求报文段，其中第一个丢失，第二个到达了服务端，但是第一个丢失的报文段只是在某些网络结点长时间滞留了，延误到连接释放以后的某个时间才到达服务端，此时服务端误认为客户端又发出一次新的连接请求，于是就向客户端发出确认报文段，同意建立连接，不采用三次握手，只要服务端发出确认，就建立新的连接了，此时客户端忽略服务端发来的确认，也不发送数据，则服务端一致等待客户端发送数据，浪费资源。

### 1.2 什么是半连接队列？


服务器第一次收到客户端的 SYN之后，就会处于 SYN_RCVD状态，此时双方还没有完全建立其连接，服务器会把此种状态下请求连接放在一个队列里，我们把这种队列称之为半连接队列。

当然还有一个全连接队列，就是已经完成三次握手，建立起连接的就会放在全连接队列中。如果队列满了就有可能会出现丢包现象。

这里在补充一点关于SYN-ACK重传次数的问题：

服务器发送完SYN-ACK包，如果未收到客户确认包，服务器进行首次重传，等待一段时间仍未收到客户确认包，进行第二次重传。如果重传次数超过系统规定的最大重传次数，系统将该连接信息从半连接队列中删除。

注意，每次重传等待的时间不一定相同，一般会是指数增长，例如间隔时间为 1s，2s，4s，8s…

### 1.3 ISN(Initial Sequence Number)是固定的吗？

当一端为建立连接而发送它的SYN时，它为连接选择一个初始序号。ISN随时间而变化，因此每个连接都将具有不同的ISN。ISN可以看作是一个32比特的计数器，每4ms加1。这样选择序号的目的在于防止在网络中被延迟的分组在以后又被传送，而导致某个连接的一方对它做错误的解释。

三次握手的其中一个重要功能是客户端和服务端交换 ISN(Initial Sequence Number)，以便让对方知道接下来接收数据的时候如何按序列号组装数据。如果 ISN是固定的，攻击者很容易猜出后续的确认号，因此 ISN是动态生成的。

### 1.4三次握手过程中可以携带数据吗？

其实第三次握手的时候，是可以携带数据的。但是，第一次、第二次握手不可以携带数据

为什么这样呢?大家可以想一个问题，假如第一次握手可以携带数据的话，如果有人要恶意攻击服务器，那他每次都在第一次握手中的 SYN报文中放入大量的数据。因为攻击者根本就不理服务器的接收、发送能力是否正常，然后疯狂着重复发 SYN报文的话，这会让服务器花费很多时间、内存空间来接收这些报文。

也就是说，第一次握手不可以放数据，其中一个简单的原因就是会让服务器更加容易受到攻击了。而对于第三次的话，此时客户端已经处于 ESTABLISHED状态。对于客户端来说，他已经建立起连接了，并且也已经知道服务器的接收、发送能力是正常的了，所以能携带数据也没啥毛病。

### 1.5 SYN攻击是什么？

服务器端的资源分配是在二次握手时分配的，而客户端的资源是在完成三次握手时分配的，所以服务器容易受到SYN洪泛攻击。SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server则回复确认包，并等待Client确认，由于源地址不存在，因此Server需要不断重发直至超时，这些伪造的SYN包将长时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络拥塞甚至系统瘫痪。SYN攻击是一种典型的 DoS/DDoS攻击。

检测 SYN攻击非常的方便，当你在服务器上看到大量的半连接状态时，特别是源IP地址是随机的，基本上可以断定这是一次SYN攻击。在 Linux/Unix上可以使用系统自带的 netstats命令来检测 SYN攻击。


netstat -n -p TCP | grep SYN_RECV

### 常见的防御 SYN攻击的方法有如下几种：

缩短超时（SYN Timeout）时间

增加最大半连接数。

过滤⽹网关防护

 SYN cookies技术

## 断开连接

这由TCP的半关闭（half-close）造成的。所谓的半关闭，其实就是TCP提供了连接的一端在结束它的发送后还能接收来自另一端数据的能力。TCP的连接的拆除需要发送四个包，因此称为四次挥手(Four-way handshake)，客户端或服务器均可主动发起挥手动作。

刚开始双方都处于 ESTABLISHED状态，假如是客户端先发起关闭请求。四次挥手的过程如下：

第一次挥手：客户端发送一个 FIN报文，报文中会指定一个序列号。此时客户端处于 FIN_WAIT1状态。

即发出连接释放报文段（FIN=1，序号seq=u），并停止再发送数据，主动关闭TCP连接，进入
FIN_WAIT1（终止等待1）状态，等待服务端的确认。

第二次挥手：服务端收到 FIN之后，会发送 ACK报文，且把客户端的序列号值 +1作为 ACK报文的序列号值，表明已经收到客户端的报文了，此时服务端处于 CLOSE_WAIT状态。

即服务端收到连接释放报文段后即发出确认报文段（ACK=1，确认号ack=u+1，序号seq=v），服务端进入CLOSE_WAIT（关闭等待）状态，此时的TCP处于半关闭状态，客户端到服务端的连接释放。客户端收到服务端的确认后，进入FIN_WAIT2（终止等待2）状态，等待服务端发出的连接释放报文段。

第三次挥手：如果服务端也想断开连接了，和客户端的第一次挥手一样，发给 FIN报文，且指定一个序列号。此时服务端处于 LAST_ACK的状态。

即服务端没有要向客户端发出的数据，服务端发出连接释放报文段（FIN=1，ACK=1，序号seq=w，确认号ack=u+1），服务端进入LAST_ACK（最后确认）状态，等待客户端的确认。

第四次挥手：客户端收到 FIN之后，一样发送一个 ACK报文作为应答，且把服务端的序列号值 +1作为自己 ACK报文的序列号值，此时客户端处于 TIME_WAIT状态。需要过一阵子以确保服务端收到自己的ACK报文之后才会进入 CLOSED状态，服务端收到 ACK报文之后，就处于关闭连接了，处于 CLOSED
状态。

即客户端收到服务端的连接释放报文段后，对此发出确认报文段（ACK=1，seq=u+1，ack=w+1），客户端进入TIME_WAIT（时间等待）状态。此时TCP未释放掉，需要经过时间等待计时器设置的时间
2MSL后，客户端才进入CLOSED状态。

收到一个FIN只意味着在这一方向上没有数据流动。客户端执行主动关闭并进入TIME_WAIT是正常的，服务端通常执行被动关闭，不会进入TIME_WAIT状态。

在socket编程中，任何一方执行close()操作即可产生挥手操作。

### 2.1 断开为什么需要四次？

因为当服务端收到客户端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当服务端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉客户端，“你发的FIN报文我收到了”。只有等到我服务端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四次挥手。

### 2.2 2MSL等待状态


TIME_WAIT状态也成为2MSL等待状态。每个具体TCP实现必须选择一个报文段最大生存时间
MSL（Maximum Segment Lifetime），它是任何报文段被丢弃前在网络内的最长时间。这个时间是有限的，因为TCP报文段以IP数据报在网络内传输，而IP数据报则有限制其生存时间的TTL字段。

对一个具体实现所给定的MSL值，处理的原则是：当TCP执行一个主动关闭，并发回最后一个ACK，该连接必须在TIME_WAIT状态停留的时间为2倍的MSL。这样可让TCP再次发送最后的ACK以防这个ACK丢失（另一端超时并重发最后的FIN）。

这种2MSL等待的另一个结果是这个TCP连接在2MSL等待期间，定义这个连接的插口（客户的IP地址和端口号，服务器的IP地址和端口号）不能再被使用。这个连接只能在2MSL结束后才能再被使用。

### 2.3 四次挥手释放连接时，等待2MSL的意义?

MSL是Maximum Segment Lifetime的英文缩写，可译为“最长报文段寿命”，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。

为了保证客户端发送的最后一个ACK报文段能够到达服务器。因为这个ACK有可能丢失，从而导致处在LAST-ACK状态的服务器收不到对FIN-ACK的确认报文。服务器会超时重传这个FIN-ACK，接着客户端再重传一次确认，重新启动时间等待计时器。最后客户端和服务器都能正常的关闭。假设客户端不等待2MSL，而是在发送完ACK之后直接释放关闭，一但这个ACK丢失的话，服务器就无法正常的进入关闭连接状态。

两个理由：

- 保证客户端发送的最后一个ACK报文段能够到达服务端。

这个ACK报文段有可能丢失，使得处于LAST-ACK状态的B收不到对已发送的FIN+ACK报文段的确认，服务端超时重传FIN+ACK报文段，而客户端能在2MSL时间内收到这个重传的FIN+ACK报文段，接着客户端重传一次确认，重新启动2MSL计时器，最后客户端和服务端都进入到CLOSED状态，若客户端在TIME-WAIT状态不等待一段时间，而是发送完ACK报文段后立即释放连接，则无法收到服务端重传的FIN+ACK报文段，所以不会再发送一次确认报文段，则服务端无法正常进入到CLOSED状态。

- 防止“已失效的连接请求报文段”出现在本连接中。

客户端在发送完最后一个ACK报文段后，再经过2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失，使下一个新的连接中不会出现这种旧的连接请求报文段。

## tcp和udp区别

TCP全称为传输控制协议。这种协议可以提供面向连接的、可靠的、点到点的通信。

UDP全称为用户数据报协议，它可以提供非连接的不可靠的点到多点的通信。

tcp面向连接，udp无连接

udp没有确认机制,没有重传机制;不太安全

udp面向数据报：应用层交给UDP多长的报文, UDP原样发送,既不会拆分,也不会合并。

tcp如何保证有序

TCP协议将数据切分为多个小片段（数据被划分为合理长度），小片段由头部（header）和数据
（payload）组成，为了确保抵达数据的顺序，TCP协议给每个片段的头部（header）都分配了序列号，方便后期按照序列号排序。

### tcp为什么有拥塞控制


TCP拥塞控制的目标是最大化利用网络上瓶颈链路的带宽，避免丢包。



# 操作系统概论

## 用户态


用户态为应用程序提供运行的空间，为了使应用程序访问到内核管理的资源例如 CPU，内存，I/O，网络。

内核必须提供一组通用的访问接口，这些接口就叫系统调用。

应用程序访问内核的方式：

系统调用：

库函数：

库函数就是屏蔽这些复杂的底层实现细节，减轻程序员的负担，从而更加关注上层的逻辑实现。

glibc：open()，write()，read()

shell 命令解释：

## 分段分页

### 什么是分段

支持将内存看作一组不同长度的段，这些段之间并没有一定的顺序。

### 什么是分页

物理内存分为固定大小的块（frame），逻辑内存也分为固定大小的块（page），利用一个页表（或者TLB）来管理 page和 frame的映射关系。

在执行一个进程时，会从文件系统或备份存储源处，加载到内存的可用 frame。

分页规避了外部碎片和紧缩。避免了将不同大小的内存块匹配到交换空间的麻烦问题。

### 保护模式（为什么要有保护模式）

实模式是有很大弊端的，首先，直接操作物理内存，这样的话每次只能运行一个程序，并且不安全；另外，内存最大使用到1M，限制太大。

保护模式下，程序不能直接访问物理地址，程序的虚拟地址需要被转换为物理地址后再去访问，地址转换是由处理器和操作系统协作完成的，处理器在硬件上提供地址转换部件，操作系统提供转换过程中需要的页表。

### 地址转换

内存控制单元(MMU)通过一种称为分段单元的硬件电路把一个逻辑地址转换成线性地址，接着，通过第二个称为分页单元的硬件电路把线性地址转换成物理地址。

分页的作用 -将线性地址转换为物理地址 -用大小相同的页替换大小不同的段

**页表的缓存MMU**（内存管理单元）中有一个TLB对于页表的缓存，一般存一页数据，是近期访问的页帧转换表项的缓存（这也是后序页面置换算法的参考点）。

多级页表解决了时间的开销，再看看空间的代价。由于逻辑地址空间很大，所以需要很大的页表，为了使页表所占的空间变小，所以可以使用多级页表。

### 局部页面置换算法

**最优页面置换算法（OPT）**：把将来最长时间不需要的页面置换。

**先进先出算法（FIFO）**：将内存中驻留时间最长的页面置换。

**最近最久未使用（LRU）**：选择最久未使用的那个页面置换。

**最不常用法（LFU）**：当缺页中断发生时，将访问次数最少的那个页面置换。

### 分段分页策略的几个考虑点：

交换：

能否支持从内存交换到外存，再从外存交换到内存

共享：

多道程序设计，让不同的进程共享代码和数据。

保护：

操作系统需要保证对于代码和数据的共享是需要限制权限的，可读可写，可执行，只读只写。

## 多线程开发经验，锁机制，并根据场景选用最佳锁


互斥锁，条件锁，自旋锁，读写锁。

使用场景，考虑实际线程的行为来做锁，对于多线程的开销出发。

互斥锁：mutex（mutual exclusive）即互斥量（互斥体）。多线程共享一个互斥量，然后线程之间去竞争。得到锁的线程可以进入临界区执行代码。互斥锁的开销主要在内核态与用户态的切换。申请锁时，从用户态进入内核态，申请到后从内核态返回用户态（两次切换）；没有申请到时阻塞睡眠在内核态。使用完资源后释放锁，从用户态进入内核态，唤醒阻塞等待锁的进程，返回用户态（又两次切换）。如果加锁执行的程序一般保持锁时间都比较长，因此选择互斥锁来睡眠。

条件变量：

线程间的通讯机制，并且几乎总是和互斥量一起使用的。

读写锁：

一般就是读共享，写独占的锁。适用于多读少写的场景。

自旋锁：

忙等待。程序不会出现大量的上下文切换，比较占CPU。如果加锁执行的程序一般保持锁时间都非常短，因此选择自旋锁来忙等待。

## 进程


1. 程序的基本执行实体，进程包括文本段（代码段），进程堆栈（临时数据，函数参数，返回地址，
局部变量），数据段（全局变量），堆（动态分配内存），进程的活动（程序计数器的值和寄存器的值）。
2. 程序运行的过程：建立虚拟空间（分配一个页文件夹）-&gt;建立虚拟空间与可运行文件映射（页文
件夹项指向磁盘的程序）-&gt;跳到程序入口 -&gt;缺页异常-&gt;在内存中寻找空暇页。将相应的页换入 -&gt;建立映射 -&gt;開始运行。

### 进程之间私有和共享的资源

私有：堆、全局变量、栈
共享：代码段，进程目录，进程 ID

### 线程之间私有和共享的资源


私有：线程栈
共享：堆，全局变量，静态变量

### 多线程和多进程的使用比较上


线程被调度的时候需要进行上下文切换，这个操作是一种额外的开销。线程数量过多的时候，上下文切换产生的额外开销会对系统的效率造成负面影响。

1. 读取相同内存地址上——没有差别
2. 写入相同的内存地址——线程编程更加方便
3. 读写相邻、但不相同的内存地址——进程效率高
4. 任务数量远超 CPU核数——线程切换代价小
5. 内存有限——线程节省内存

### 线程同步的方法


临界区（Critical Section）、互斥对象（Mutex）：信号量（Semaphore）、事件对象（Event）

### 进程、线程、时间片


Linux内核其实不区分进程和线程，内核把执行单元叫做任务(task)。

在Linux系统中，对于用户创建的进程(线程)来说，CPU分配时间片的单位是线程。

线程是实际工作的单元[1]，进程只是一个容器，用来管理一个或多个线程。

## 进程调度


Linux调度

### （完全公平）CFS调度

CFS调度程序并不采用严格规则来为一个优先级分配某个长度的时间片，而是为每个任务分配一定比例
的 CPU处理时间。每个任务分配的具体比例是根据nice值来计算的。（根据nice值来计算每个任务分配的比例）

nice值的范围从 -20到 +19，默认nice值为 0。数值较低的nice值表示较高的相对优先级。具有较低nice值的任务，与具有较高nice值的任务相比，会得到更高比例的处理器处理时间。

Linux CFS调度程序釆用高效算法，以便选择运行下个任务。每个可运行的任务放置在红黑树上（这是一种平衡的、二分搜索树，它的键是基于虚拟运行时间的）。

当一个任务变成可运行时，它被添加到树上。当一个任务变成不可运行时（例如，当阻塞等待 I/O
时），它从树上被删除。一般来说，得到较少处理时间的任务（虚拟运行时间较小）会偏向树的左侧；得到较多处理时间的任务会偏向树的右侧。根据二分搜索树的性质，最左侧的结点有最小的键值；从CFS调度程序角度而言，这也是具有最高优先级的任务。由于红黑树是平衡的，找到最左侧结点会需要
O(lgN) 操作（这里 N为树内结点总数）。不过，为高效起见，Linux调度程序将这个值缓存在变量rb_leftmost中，从而确定哪个任务运行只需检索缓存的值。

### 实时调度

采用 SCHED_FIFO或 SCHED_RR实时策略来调度的任何任务，与普通（非实时的）任务相比，具有更高的优先级。

Linux采用两个单独的优先级范围，一个用于实时任务，另一个用于正常任务。实时任务分配的静态优先级为 0〜99，而正常任务分配的优先级为 100〜139。

## 进程间通信


管道的通知机制类似于缓存，就像一个进程把数据放在某个缓存区域，然后等着另外一个进程去拿，并且是管道是单向传输的。

缺点：这种通信方式效率低下，你看，a进程给 b进程传输数据，只能等待 b进程取了数据之后 a 进程才能返回。

### 消息队列

例如 a进程要给 b进程发送消息，只需要把消息放在对应的消息队列里就行了，b进程需要的时候再去对应的。

这种通信方式也类似于缓存吧。

缺点：如果 a进程发送的数据占的内存比较大，并且两个进程之间的通信特别频繁的话，消息队列模型就不大适合了。因为 a发送的数据很大的话，意味发送消息（拷贝）这个过程需要花很多时间来读内存。

### 共享内存

两个进程虽然有着独立的虚拟内存空间，但有一部分却是映射到相同的物理内存，这就完成了内存共享机制了。

单纯地使用会存在竞争问题。

### 信号量

本质就是一个计数器，实现进程之间的互斥与同步。

进程独占时是信号为 0，没有占用时为 1。

### socket通信

主机之间的通信。

## Q & A

### 线程是否具有相同的堆栈 dll是否有独立的堆栈


如果是全局变量，所有线程都是可以访问的；如果是栈变量，那无论哪个线程只要执行该函数，它就可以访问它的栈变量；如果是线程变量（linux下gcc使用__thread标识符创建的变量/ thread_local）的确是每线程一份的，如果不采用特殊技巧，每个线程只能访问自己的那份。

每个DLL有自己的堆，所以如果是从DLL中动态分配的内存，最好是从DLL中删除。

最好动态链接库去维护自己堆上的内存。

### linux用户级进程跟内核线程（进程）有什么差别


内核级就是操作系统内核支持，用户级就是函数库实现（也就是说，不管操作系统是不是支持线程的，都是可以在上面用多线程编程）。

操作系统创建的线程，自然是内核级的了

Linux下用pthread创建的线程是“内核级线程”。

用户级线程，内核级线程关联性：

（1）它们之间的差别在于性能。（2）内核支持线程是OS内核可感知的，而用户级线程是OS内核不
可感知的。（3）用户级线程的创建、撤消和调度不需要OS内核的支持。（4）用户级线程执行系统调用指令时将导致其所属进程被中断，而内核支持线程执行系统调用指令时，只导致该线程被中断。
（5）在只有用户级线程的系统内，CPU调度还是以进程为单位，处于运行状态的进程中的多个线程，
由用户程序控制线程的轮换运行；在有内核支持线程的系统内，CPU调度则以线程为单位，由OS的线程调度程序负责线程的调度。（6）用户级线程的程序实体是运行在用户态下的程序，而内核支持线程的程序实体则是可以运行在任何状态下的程序。

### 异步，多线程和并行的区别


多线程是对cpu剩余劳动力的压榨，是一种技术，强调的是并发（想想web server需要处理大量并发请求的场景）。

异步强调的是非阻塞，是一种编程模式（pattern），主要解决了UI响应被阻塞的问题，可借助线程技术或者硬件本身的计算能力解决。

并行，基于多核cpu，也是基于多线程技术，多个任务同时进行，而不是并发数量。

### 线程安全 &amp;静态变量初始化

线程安全：

在拥有共享数据的多条线程并行执行的程序中，线程安全的代码会通过同步机制保证各个线程都可以正常且正确的执行，不会出现数据污染等意外情况。

C++11保证静态局部变量的初始化过程是线程安全的。

这里的线程安全并不是说：由于m只能被初始化一次，所以只有初始化m的线程会阻塞，另外一个就立即跳过初始化过程返回了。

### share_ptr的线程安全性


C++标准里面有说明 use_count无（data race）数据竞争，所以 shared_ptr的析构是线程安全的。

C++标准以及标准的实现保证这一动作的线程安全性。

对同一个对象分享所有权的 shared_ptr在多个线程上的析构不需要外部加锁保护。

## 死锁


死锁：

死锁产生的条件：1.互斥条件 2.请求与保持条件（一个进程因请求资源而阻塞时，对已获得的资源保持不变）3.不剥夺条件（进程已获得的资源，在没使用完全时，不可强行剥夺）4.循环等待条件，多个进程之间形成一种互相循环等待资源的关系

避免死锁：1.加锁顺序，线程排队 2.加锁时限，超时回退释放锁 3.死锁检测，记录锁。

# 设计模式

## 五（六）大原则


单一职责原则（SRP，Single Responsibility Principle）：一个类应该仅有一个引起它变化的原因变化的方向隐含着类的责任
里氏替换原则（LSP，Liskov Substitution Principle）：子类必须能够替换他们的基类，继承表达类型抽象
依赖倒置原则（DIP，Dependence Inversion Principle）：高层模块（稳定）不应该依赖于低层模块（变化），二者都应该依赖于抽象（稳定）。抽象（稳定）不应该依赖于实现细节（变化），实现细节应该依赖于抽象（稳定）
接口隔离原则（ISP，Interface Segregation Principle）：不应该强迫外部程序依赖他们不用的接口，接口应该小而完备
开放封闭原则（OCP，Open Close Principle）对扩展开放，对修改封闭，类模块是可扩展的，但是不可修改

## 工厂模式


工厂模式：

定义一个创建对象的接口，让其子类自己决定实例化哪一个工厂类,

工厂模式使其创建过程延迟到子类进行。我们明确地计划不同条件下创建不同实例时。


抽象工厂模式：提供一个接口，创建一系列相关依赖的对象创建工作。工厂创建类之前存在强关联性，将几个相互依赖的对象创建工作封装，形成一个抽象工厂。

## 单例模式


单例模式是一个经典常用的设计模式，当整个进程需要使用唯一的实例时，可以考虑使用单例模式，单例模式有几个关键点：

类只能有一个实例。
外部用户不能也无法自行对类进行实例化，实例化的操作需要类内部去实现。
整个进程共用一个类的实例，且需要是线程安全的。

示例代码：

```c++
class DataFlowManager{
public:
EngineManager(EngineManager const &amp;) = delete;
void operator=(EngineManager const &amp;) = delete;
static EngineManager *global();

private:
EngineManager() = default;

DataFlowManager *DataFlowManager::global() {
static DataFlowManager *manager = new DataFlowManager;
return manager;
} 
DataFlowManager *DataFlowManager::global() {
static DataFlowManager *manager = new DataFlowManager; return manager;
}
```

C++ call_once

```c++
 
template <typename T>
class SingleTon {
public:
 SingleTon(const SingleTon&) = delete;
 SingleTon& operator=(const SingleTon&) = delete;
 static T& instance() { 
  std::call_once(once_, &SingleTon::init); 
  return *value_;
 }
private: 
  SingleTon(); 
  ~SingleTon();
  static void init() { value_ = new T(); }
  static T* value_;
  static std::once_flag once_;
};
```

## 修饰者模式

采用类组合而非继承的方法。Decorator类接口上为表现为继承关系，实现上为组合关系。解决主体类的扩展问题。

## 观察者模式

当对象间存在一对多关系时，则使用观察者模式（Observer Pattern）。比如，当一个对象被修改时，则会自动通知它的依赖对象。

对象依赖关系（通知类），

观察者模式属于行为型模式。

观察者对象决定是否需要订阅哪些对应修改的对象，目标主体对象无需知道。



# 多态

## 实现多态


1. 重载在编译时编译器会根据参数列表的不同寻找合适的函数。
2. 使用虚函数实现多态纯虚函数，子类重写由关键字 virtual修饰的虚函数运行时多态的条件：必
须是集成关系基类中必须包含虚函数，并且派生类中一定要对基类中的虚函数进行重写。通过基类对象的指针或者引用调用虚函数。

3. 虚函数的实现原理一个类中如果有虚函数声明，那么这些函数会由一个虚函数表来维护 1）每个
父类都有自己的虚表。2）子类的成员函数被放到了第一个父类的表中。3）内存布局中，其父类布局依次按声明顺序排列。4）首先需要取到对象的首地址，然后再解引用取到虚函数表的首地址后，再加上偏移量才能找到要调的虚函数。5）同一个类的多个对象的虚函数表是同一个，所以这样就可以节省空间，一个类自己的虚函数和继承的虚函数还有重写父类的虚函数都会存在自己的虚函数表。

## 动态联编和静态联编的区别：


静态联编：在编译的时候就确定了函数的地址，然后call就调用了。

动态联编：首先需要取到对象的首地址，然后再解引用取到虚函数表的首地址后，再加上偏移量才能找到要调的虚函数，然后call调用。

明显动态联编要比静态联编做的操作多，肯定就费时间。

# 析构函数


1. 为多态基类声明 virtual析构函数（如果 class带有任何 virtual函数，它就应该拥有一个 virtual
析构函数）当我们使用多态机制时，父类的指针指向派生类时，如果析构函数未定义为虚函数，则使用的析构函数仍为父类的析构函数，导致内存泄漏。

虚析构函数是为了解决基类的指针指向派生类对象，并用基类的指针删除派生类对象。

2. 绝不在构造和析构过程中调用 virtual函数（因为这类调用从不下降至 derived class）。

3. 别让异常逃离析构函数（析构函数应该吞下不传播异常，或者结束程序，而不是吐出异常；如果要
处理异常应该在非析构的普通函数处理）

# 构造函数


什么时候会调用拷贝构造函数


1. 当用类一个对象去初始化另一个对象时。
2. 如果函数形参是类对象。
3. 如果函数返回值是类对象，函数执行完成返回调用时。

构造函数不能声明为虚函数


1. 构造一个对象的时候，必须知道对象的实际类型，而虚函数行为是在运行期间确定实际类型的。
2. 构造对象期间，虚函数表还没有被初始化，将无法进行。虚函数表需要内存空间，而构造函数是用
来开辟空间，互相矛盾。

四种构造函数

```c++
 
class A {
public:
  A () = defalut;
  A (T a) : a_(a.a_) {}
  A (int a) { a_ = a;}
  A& operator = (int a) : a_(a) {
    return *this;
  }
  A (T &&a) : a_(a.a_) {} 
private:
  int a_; 
};
```


类成员初始化列表


好处高效：少了一次调用默认构造函数的过程。必须要用初始化列表：

1. 常量成员，因为常量只能初始化不能赋值，所以必须放在初始化列表里面
2. 引用类型，引用必须在定义的时候初始化，并且不能重新赋值，所以也要写在初始化列表里面3. 没有默认构造函数的类类型，因为使用初始化列表可以不必调用默认构造函数来初始化，而是直接
调用拷贝构造函数初始化。

# 内存

## new和malloc


new / new[]：完成两件事，先底层调用malloc分了配内存，然后调用构造函数（创建对象）。

malloc：申请指定字节数的内存。申请到的内存中的初始值不确定。

注：malloc和 free是线程安全，在多线程开发时不需要注意

## static


static 全局变量与普通的全局变量有什么区别：

static 全局变量只初使化一次，防止在其他文件单元中被引用;

static 局部变量和普通局部变量有什么区别：

static 局部变量只被初始化一次，下一次依据上一次结果值；

static 函数与普通函数有什么区别：

static 函数在内存中只有一份，普通函数在每个被调用中维持一份拷贝

1. 隐藏（解决命名冲突）
2. 初始化一次（静态数据区，内存中所有的字节默认值都是0x00）
3. 全局生存期（线程安全问题）


static类成员函数（无 this，仅访问静态成员，不能是虚函数，可以是 callback函数）

static类成员变量（必须手动初始化）

静态成员常量可以在类内定义时直接初始化，也可以像静态成员变量一样类内声明，类外定义；

static命名构造函数，会更加直观和安全。（构造器多）

## 堆和栈

### 栈：

由编译器自动分配释放，存放函数的参数值，局部变量的值等。

申请：由系统自动分配。

内存：是一块连续的内存的区域，栈顶的地址，栈的最大容量是系统预先规定好的

速度：栈由系统自动分配，速度较快。

### 堆：

一般由程序员分配释放，若程序员不释放，程序结束时可能由OS回收。

申请：程序动态申请。

内存：堆是向高地址扩展的数据结构，是不连续的内存区域。系统是用链表来存储的空闲内存地址的，自然是不连续的，而链表的遍历方向是由低地址向高地址。堆的大小受限于计算机系统中有效的虚拟内存。

速度：一般速度比较慢，而且容易产生内存碎片。

内部碎片的产生：实际获取到的空间会比申请的内存更大，多余空间就叫内部碎片。

外部碎片的产生：频繁的分配与回收物理页面会导致大量的、连续且小的页面块夹杂在已分配的页面中间，就会产生外部碎片，没有办法分配给进程。

首先应该知道操作系统有一个记录空闲内存地址的链表，当系统收到程序的申请时，会遍历该链表，寻找第一个空间大于所申请空间的堆结点，然后将该结点从空闲结点链表中删除，并将该结点的空间分配给程序，另外，对于大多数系统，会在这块内存空间中的首地址处记录本次分配的大小，这样，代码中的delete语句才能正确的释放本内存空间。另外，由于找到的堆结点的大小不一定正好等于申请的大小，系统会自动的将多余的那部分重新放入空闲链表中。

优点：使用灵活。

## 二维矩阵按行和列的遍历效率

二维矩阵在内存中按行存储的。

横向顺序访问会比较快。为了提高 cache命中率，降低 cache刷新，降低 CPU访问主存的时间。

内存对齐，内存连续。

thread太多会引起 cache争用。

## 智能指针

### shared_ptr


定义：

智能指针，自动管理

成员函数：

1. use_count比较耗时，一般是调试 debug的时候使用
2. reset，reset重置新的一个 shared_ptr对象
3. get返回内部对象(指针),由于已经重载了()方法,因此和直接使用对象是一样的
4. unique返回是否是独占所有权( use_count为 1)

问题：

1. 为什么要使用智能指针：所以智能指针的作用原理就是在超出其作用域结束时自动释放内存空
间，不需要手动释放内存空间，并且会自动调用析构函数。

程序需要在多个对象间共享数据。

程序不知道自己需要使用多少对象。如某个类使用 shared_ptr为了让多个对象能共享相同的底层数据。

2. 引用计数递增的情况：用一个 shared_ptr给另一个 shared_ptr赋值用一个 shared_ptr初始化
另一个 shared_ptr将 shared_ptr作为参数传递给一个函数 shared_ptr作为函数的返回值

3. 引用计数递减的情况：给 shared_ptr赋予一个新值 shared_ptr被销毁（如离开作用域）

4. 使用 shared_ptr注意事项

shared_ptr使用裸指针作为实参时，会创建一个控制块，如果多次创建，这些 shared_ptr会引起多次释放同一内存。

循环引用。

### unique_ptr


定义：

unique_ptr和 shared_ptr的不同点

是否可以让多个指针指向相同的对象。

### weak_ptr


构造和析构不会引起引用记数的增加或减少。

# C++语法

## class


利用初始化列表初始化 const和引用成员

委托构造函数

## 类构造函数为 protected

protected函数，只能造子类内部和本类内部调用，限制外部随意构造对象，需要限制对象存在的个数，引申单例模式

## 继承

## 封装

##多态

C++用虚函数实现多态

## RAII


Resource Acquisition is Initialization，在构造函数中申请分配资源，在析构函数中释放资源。

智能指针，可以实现自动的内存管理。

文件的打开与关闭。

使用std::unique_lock或者std::lock_guard对互斥量std:: mutex进行状态管理。

RAII的核心思想是将资源或者状态与对象的生命周期绑定，通过C++的语言机制，实现资源和状态的安全管理。

## explicit


隐式类型转换：修饰的构造函数可用来防止隐式转换。

## std::move


左值，指的是如果一个表达式可以引用到某一个对象，并且这个对象是一块内存空间且可以被检查和存储，那么这个表达式就可以作为一个左值。

右值，指的是引用了一个存储在某个内存地址里的“数据”。常数，字符串。

### 左值和右值：

1. &amp;&amp;获取右值引用
2. 右值引用可以绑定到返回右值的表达式，但不能绑定左值
3. 左值有持久的状态，右值是字面常量或者是表达式求值过程中创建的临时对象。
4. 变量是左值。

### 右值的应用场景：

按值传入参数；

对象存入容器；std::vector::push_back

unique_ptr的传递；

move为获取绑定左值的右值引用。

类必须要有移动构造函数，内置类型是可以移动的。含有拷贝构造函数的类类型必须有显示的移动构造函数，否则是编译器默认是删除的。

移动后的对象是不确定的状态，内存。

## std::forward


std::forward被称为完美转发，它的作用是保持原来的值属性不变。

紧接着std::forward模板函数对传入的参数进行强制类型转换，转换的目标类型符合引用折叠规则，因此左值参数最终转换后仍为左值，右值参数最终转成右值。

## 引用折叠原理


A&amp; + A&amp; = A&amp; A&amp; + A&amp;&amp; = A&amp; A&amp;&amp; + A&amp; = A&amp; A&amp;&amp; + A&amp;&amp; = A&amp;&amp;

## reinterpret_cast

## 使用 C++ xxx_cast而不用 C类型的转换


1. C++ xxx_cast可以在编译时期可以检查可行性，但是 C类型不能
2. C++ xxx_cast可以简单的在代码里看到
3. C++ xxx_cast代码意图很明显，C类型的转换对开发人员的行为不能明显反馈。

## 模版


支持函数模版的默认模版参数

别名 using：代码简洁易读，typedef定义函数指针的操作

右尖括号（以前是右移 &gt;&gt;）

## final &amp; override


final修饰类，防止进一步派生和虚函数的进一步重载。

override修饰派生类的成员函数，重写基类的成员函数。避免在重写基类函数时发生的不必要产生的错误。

## default &amp; delete


函数声明后 + “=default”，函数声明为 default函数

delete禁止函数

explicit

修饰构造函数，显示构造，不可以隐式转换

## const &amp; constexpr


const只是 read_only

constexpr真正的常量，编译时期计算出来。也可以修饰函数，如果可以在编译时期算出来，则计算出来。

# 程序从代码到执行的过程


1. 预处理，主要处理源代码文件中的以“#”开头的预编译指令。
   1. 删除所有的#define，展开所有的宏定义。
   2. 处理所有的条件预编译指令，如“#if”、“#endif”、“#ifdef”、“#elif”和“#else”。
   3. 处理 “#include”预编译指令，将文件内容替换到它的位置，这个过程是递归进行的，文件中包含其他文件。
   4. 删除所有的注释，“//”和“/**/”。
   5. 保留所有的#pragma编译器指令，编译器需要用到他们，如：#pragma once是为了防止有文件被重复引用。6.添加行号和文件标识，便于编译时编译器产生调试用的行号信息，和编译时产生编译错误或警告是能够显示行号。


2. 编译，预处理后的文件不转换成汇编语言，词法分析、语法分析、语义分析及优化后，生成相应的
汇编代码文件。

3. 汇编变为目标代码，目标代码优化器对上述的目标机器代码进行优化：寻找合适的寻址方式、使用
位移来替代乘法运算、删除多余的指令等。

4. 链接，目标代码,生成可执行程序[链接器ld]

1. 链接的过程：地址和空间的分配、符号决议(也叫“符号绑定”，倾向于动态链接)和重定位。

# 常见面试算法题

## 字符串反转

1. string::substr(start, lenght);


2. string::find(char, start_pos)
3. 双指针
4. 题意
5. 边界跳出的时候

## 合并两个有序链表

## 如何判断一个链表有环

## 两个栈实现一个队列

## 如何取到链表倒数第k个数

## 二分查找找出有序数组第一次出现的位置

## LRU


理念：

利用 HasMap维护 key-value

利用 List维护最近使用

插入操作：

如果 List容量 =最大，删除最后一个，插入到头部。


查询操作：

hasmap中存在，把其在链表中删掉，再插入到链表头部。

## 最长递增子系列优化

## 快排原理,手写快排


分治法

原问题可以分成若干个相同性质的子问题

子问题之间相互独立

子问题的解的组合可以合并成原问题的解

## 两个矩形怎么判断重叠

## B树

## 简单实现一个shared_ptr智能指针


https://blog.csdn.net/weixin_44826356/article/details/105912215

https://blog.csdn.net/m0_38076911/article/details/107071006?utm_source=blogxgwz4

shared_ptr的原理：是通过引用计数的方式来实现多个shared_ptr对象之间共享资源。

1. shared_ptr在其内部，给每个资源都维护了着一份计数，用来记录该份资源被几个对象共享。
2. 在对象被销毁时(也就是析构函数调用)，就说明自己不使用该资源了，对象的引用计数减一。
3. 如果引用计数是0，就说明自己是最后一个使用该资源的对象，必须释放该资源；
4. 如果不是0，就说明除了自己还有其他对象在使用该份资源，不能释放该资源，否则其他对象就成
野指针了。

## BFS最短路径


有一个二维字符矩阵，共有四种字符：#——墙，不可行走，X——每个人的起点，*——迷宫出口，.——地面，可以行走求每个人走到出口的最短路径（保证每个人都可以走到出口）

## 二叉树前序和后序构造二叉树（递归 & 非递归）

## 二叉树查找两个节点的最近公共祖先。

## 单调栈求水柱大小

## 二叉搜索树的删除

1.如果待删除的结点没有孩子结点，那么直接删除就好了；

2.如果待删除的结点只有一个孩子结点，那么让孩子结点顶替他的位置；

3.如果待删除的结点有两个孩子结点，一种方法是拿左子树的最大元素来顶替他的位置，另一种方法是拿右子树的最小元素来顶替他的位置；
